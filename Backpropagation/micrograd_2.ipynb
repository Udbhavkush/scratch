{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe5158a",
   "metadata": {},
   "source": [
    "Created this file for cleaner start. The first file (micrograd.ipynb) was used for derivation and stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8dae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac9db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:  # we have created this class sort of an analogy for tensors. Just to manipulate the whole training process with some data structure\n",
    "    def __init__(self, data, _children=(), _op='', label=''):\n",
    "        self.data = data\n",
    "        self.grad = 0.0 # initialized to 0 as we assume that by default no node or weight affects the loss function. This is the derivative of loss function w.r.t. that node\n",
    "        self._prev = set(_children) # this is used to keep track of the previous nodes in the graph\n",
    "        self._backward = lambda: None  # this would be a function that would differ for all the different operators\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "    \n",
    "    def __repr__(self): # magic function to print the object. Can modify the string representation of the object when printed.\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other): # magic function to add two objects. Can modify the behavior of the + operator when applied to objects of this class. In case of a.__add__(b), a is self and b is other.\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out =  Value(self.data + other.data, (self, other), '+')\n",
    "        def _backward(): # we want to take out grad and find out the self grad and other grad, so we will set self.grad to something and other.grad to something\n",
    "            self.grad += 1.0 * out.grad # local derivative * global derivative\n",
    "            other.grad += 1.0 * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "            \n",
    "    def __mul__(self, other): # magic function to multiply two objects. Can modify the behavior of the * operator when applied to objects of this class. In case of a.__mul__(b), a is self and b is other.\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad # local derivative * global derivative\n",
    "            other.grad += self.data * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __rmul__(self, other): # other * self\n",
    "        return self * other\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "        out = Value(self.data**other, (self, ), f'**{other}')\n",
    "        \n",
    "        def _backward():\n",
    "             self.grad += other * (self.data ** (other-1)) * out.grad\n",
    "        out._backward = _backward\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def __neg__(self): # -self\n",
    "        return self * (-1)\n",
    "    \n",
    "    def __sub__(self, other): # self - other\n",
    "        return self + (-other)\n",
    "        \n",
    "    def __truediv__(self, other): # self/other\n",
    "        return self * (other ** -1)\n",
    "    \n",
    "    def __radd__(self, other): # other + self\n",
    "        return self + other\n",
    "        \n",
    "        \n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n",
    "        out = Value(t, (self, ), 'tanh')\n",
    "        def _backward():\n",
    "            self.grad += (1 - t**2) * out.grad # local derivative * global derivative\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def exp(self):\n",
    "        x = self.data\n",
    "        out = Value(math.exp(x), (self, ), 'exp')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += out.data * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "        \n",
    "        self.grad = 1.0 # base condition\n",
    "        for node in reversed(topo):\n",
    "            node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c6738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def trace(root):\n",
    "  # builds a set of all nodes and edges in a graph\n",
    "  nodes, edges = set(), set()\n",
    "  def build(v):\n",
    "    if v not in nodes:\n",
    "      nodes.add(v)\n",
    "      for child in v._prev:\n",
    "        edges.add((child, v))\n",
    "        build(child)\n",
    "  build(root)\n",
    "  return nodes, edges\n",
    "\n",
    "def draw_dot(root):\n",
    "  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
    "  \n",
    "  nodes, edges = trace(root)\n",
    "  for n in nodes:\n",
    "    uid = str(id(n))\n",
    "    # for any value in the graph, create a rectangular ('record') node for it\n",
    "    dot.node(name = uid, label = \"{ %s | data:%.4f | grad:%.4f }\" % (n.label, n.data, n.grad), shape='record')\n",
    "    if n._op:\n",
    "      # if this value is a result of some operation, create an op node for it\n",
    "      dot.node(name = uid + n._op, label = n._op)\n",
    "      # and connect this node to it\n",
    "      dot.edge(uid + n._op, uid)\n",
    "\n",
    "  for n1, n2 in edges:\n",
    "    # connect n1 to the op node of n2\n",
    "    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "\n",
    "  return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6722962a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.1.2 (20260124.0452)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1553pt\" height=\"210pt\"\n",
       " viewBox=\"0.00 0.00 1553.00 210.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 206)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-206 1549,-206 1549,4 -4,4\"/>\n",
       "<!-- 4421734480 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4421734480</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"668.25,-82.5 668.25,-118.5 925.5,-118.5 925.5,-82.5 668.25,-82.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"714.12\" y=\"-95.7\" font-family=\"Times,serif\" font-size=\"14.00\">x1w1 + x2w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"760,-83 760,-118.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"802.12\" y=\"-95.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:&#45;6.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"844.25,-83 844.25,-118.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"884.88\" y=\"-95.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:0.5000</text>\n",
       "</g>\n",
       "<!-- 4421733520+ -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4421733520+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"988.5\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"988.5\" y=\"-122.45\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 4421734480&#45;&gt;4421733520+ -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>4421734480&#45;&gt;4421733520+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M925.93,-118.73C934.56,-119.96 942.77,-121.13 950.21,-122.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"949.71,-125.65 960.1,-123.6 950.69,-118.72 949.71,-125.65\"/>\n",
       "</g>\n",
       "<!-- 4421734480+ -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4421734480+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"605.25\" cy=\"-100.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"605.25\" y=\"-95.45\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 4421734480+&#45;&gt;4421734480 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>4421734480+&#45;&gt;4421734480</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M632.62,-100.5C639.63,-100.5 647.71,-100.5 656.45,-100.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"656.32,-104 666.32,-100.5 656.32,-97 656.32,-104\"/>\n",
       "</g>\n",
       "<!-- 4421733520 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4421733520</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1051.5,-109.5 1051.5,-145.5 1235.25,-145.5 1235.25,-109.5 1051.5,-109.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1062.88\" y=\"-122.7\" font-family=\"Times,serif\" font-size=\"14.00\">n</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1074.25,-110 1074.25,-145.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1114.12\" y=\"-122.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:0.8814</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1154,-110 1154,-145.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1194.62\" y=\"-122.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:0.5000</text>\n",
       "</g>\n",
       "<!-- 4421621520tanh -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>4421621520tanh</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1298.25\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1298.25\" y=\"-122.45\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 4421733520&#45;&gt;4421621520tanh -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>4421733520&#45;&gt;4421621520tanh</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1235.51,-127.5C1243.89,-127.5 1252.02,-127.5 1259.48,-127.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1259.45,-131 1269.45,-127.5 1259.45,-124 1259.45,-131\"/>\n",
       "</g>\n",
       "<!-- 4421733520+&#45;&gt;4421733520 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4421733520+&#45;&gt;4421733520</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1015.78,-127.5C1022.92,-127.5 1031.11,-127.5 1039.82,-127.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1039.56,-131 1049.56,-127.5 1039.56,-124 1039.56,-131\"/>\n",
       "</g>\n",
       "<!-- 4365350032 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4365350032</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3.75,-55.5 3.75,-91.5 194.25,-91.5 194.25,-55.5 3.75,-55.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"18.5\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">x2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"33.25,-56 33.25,-91.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"73.12\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:0.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"113,-56 113,-91.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"153.62\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:0.5000</text>\n",
       "</g>\n",
       "<!-- 4421734672* -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>4421734672*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"261\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"261\" y=\"-68.45\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 4365350032&#45;&gt;4421734672* -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>4365350032&#45;&gt;4421734672*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.46,-73.5C204.21,-73.5 213.66,-73.5 222.21,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.12,-77 232.12,-73.5 222.12,-70 222.12,-77\"/>\n",
       "</g>\n",
       "<!-- 4421734096 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4421734096</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"324,-110.5 324,-146.5 542.25,-146.5 542.25,-110.5 324,-110.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"350.38\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">x1*w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"376.75,-111 376.75,-146.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"418.88\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:&#45;6.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"461,-111 461,-146.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"501.62\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:0.5000</text>\n",
       "</g>\n",
       "<!-- 4421734096&#45;&gt;4421734480+ -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>4421734096&#45;&gt;4421734480+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M542.35,-110.69C551.12,-109.24 559.54,-107.86 567.19,-106.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"567.72,-110.06 577.02,-104.98 566.58,-103.15 567.72,-110.06\"/>\n",
       "</g>\n",
       "<!-- 4421734096* -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>4421734096*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"261\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"261\" y=\"-123.45\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 4421734096*&#45;&gt;4421734096 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4421734096*&#45;&gt;4421734096</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288.21,-128.5C295.29,-128.5 303.43,-128.5 312.17,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"312.01,-132 322.01,-128.5 312.01,-125 312.01,-132\"/>\n",
       "</g>\n",
       "<!-- 4421734672 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>4421734672</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"326.25,-55.5 326.25,-91.5 540,-91.5 540,-55.5 326.25,-55.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"352.62\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">x2*w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"379,-56 379,-91.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"418.88\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:0.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"458.75,-56 458.75,-91.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"499.38\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:0.5000</text>\n",
       "</g>\n",
       "<!-- 4421734672&#45;&gt;4421734480+ -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4421734672&#45;&gt;4421734480+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M540.42,-90.37C549.89,-91.87 559,-93.32 567.21,-94.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"566.63,-98.07 577.05,-96.18 567.72,-91.16 566.63,-98.07\"/>\n",
       "</g>\n",
       "<!-- 4421734672*&#45;&gt;4421734672 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4421734672*&#45;&gt;4421734672</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288.21,-73.5C296,-73.5 305.08,-73.5 314.82,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"314.55,-77 324.55,-73.5 314.55,-70 314.55,-77\"/>\n",
       "</g>\n",
       "<!-- 4421621520 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>4421621520</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1361.25,-109.5 1361.25,-145.5 1545,-145.5 1545,-109.5 1361.25,-109.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1372.62\" y=\"-122.7\" font-family=\"Times,serif\" font-size=\"14.00\">o</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1384,-110 1384,-145.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1423.88\" y=\"-122.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:0.7071</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1463.75,-110 1463.75,-145.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1504.38\" y=\"-122.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:1.0000</text>\n",
       "</g>\n",
       "<!-- 4421621520tanh&#45;&gt;4421621520 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4421621520tanh&#45;&gt;4421621520</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1325.53,-127.5C1332.67,-127.5 1340.86,-127.5 1349.57,-127.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1349.31,-131 1359.31,-127.5 1349.31,-124 1349.31,-131\"/>\n",
       "</g>\n",
       "<!-- 4421733648 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>4421733648</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"705,-137.5 705,-173.5 888.75,-173.5 888.75,-137.5 705,-137.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"716.38\" y=\"-150.7\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"727.75,-138 727.75,-173.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"767.62\" y=\"-150.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:6.8814</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"807.5,-138 807.5,-173.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"848.12\" y=\"-150.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:0.5000</text>\n",
       "</g>\n",
       "<!-- 4421733648&#45;&gt;4421733520+ -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>4421733648&#45;&gt;4421733520+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M889.08,-142.03C910.92,-138.81 933.02,-135.54 950.73,-132.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"951.08,-136.42 960.46,-131.49 950.06,-129.49 951.08,-136.42\"/>\n",
       "</g>\n",
       "<!-- 4421732752 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>4421732752</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1.5,-165.5 1.5,-201.5 196.5,-201.5 196.5,-165.5 1.5,-165.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"16.25\" y=\"-178.7\" font-family=\"Times,serif\" font-size=\"14.00\">x1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"31,-166 31,-201.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"70.88\" y=\"-178.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:2.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"110.75,-166 110.75,-201.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"153.62\" y=\"-178.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:&#45;1.5000</text>\n",
       "</g>\n",
       "<!-- 4421732752&#45;&gt;4421734096* -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>4421732752&#45;&gt;4421734096*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.12,-165.01C180.9,-162.35 189.7,-159.5 198,-156.5 208.09,-152.86 218.82,-148.27 228.47,-143.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"229.86,-147.09 237.45,-139.69 226.9,-140.75 229.86,-147.09\"/>\n",
       "</g>\n",
       "<!-- 4421733328 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>4421733328</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2.25,-0.5 2.25,-36.5 195.75,-36.5 195.75,-0.5 2.25,-0.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"18.5\" y=\"-13.7\" font-family=\"Times,serif\" font-size=\"14.00\">w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"34.75,-1 34.75,-36.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"74.62\" y=\"-13.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:1.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"114.5,-1 114.5,-36.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"155.12\" y=\"-13.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:0.0000</text>\n",
       "</g>\n",
       "<!-- 4421733328&#45;&gt;4421734672* -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>4421733328&#45;&gt;4421734672*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.91,-36.94C178.74,-39.93 188.67,-43.15 198,-46.5 207.96,-50.07 218.58,-54.47 228.18,-58.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.54,-61.78 237.1,-62.67 229.4,-55.39 226.54,-61.78\"/>\n",
       "</g>\n",
       "<!-- 4420360656 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>4420360656</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-110.5 0,-146.5 198,-146.5 198,-110.5 0,-110.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"16.25\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"32.5,-111 32.5,-146.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"74.62\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">data:&#45;3.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"116.75,-111 116.75,-146.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"157.38\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">grad:1.0000</text>\n",
       "</g>\n",
       "<!-- 4420360656&#45;&gt;4421734096* -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4420360656&#45;&gt;4421734096*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.14,-128.5C206.61,-128.5 214.8,-128.5 222.29,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.29,-132 232.29,-128.5 222.29,-125 222.29,-132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1078c9e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a basic neuron\n",
    "# inputs x1, x2\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "\n",
    "# weights w1, w2\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "\n",
    "# constant or bias\n",
    "b = Value(6.8813735870195432, label='b') # just to get good numbers in output, setting this value\n",
    "x1w1 = x1*w1; x1w1.label='x1*w1'\n",
    "x2w2 = x2*w2; x2w2.label='x2*w2'\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label='x1w1 + x2w2'\n",
    "n = x1w1x2w2 + b; n.label='n'\n",
    "o = n.tanh(); o.label='o'\n",
    "\n",
    "o.backward()\n",
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a2a955",
   "metadata": {},
   "source": [
    "Now we will use pytorch framework to confirm our backward progapagation values that we got using micrograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e134d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95393289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071066904050358\n",
      "_______\n",
      "x1 grad: -1.5000003851533106\n",
      "w1 grad: 1.0000002567688737\n",
      "x2 grad: 0.5000001283844369\n",
      "w2 grad: 0.0\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([2.0]).double(); x1.requires_grad = True  # python by default uses double float integer types, so converting it to double to make everything consistent  \n",
    "x2 = torch.tensor([0.0]).double(); x2.requires_grad = True\n",
    "w1 = torch.tensor([-3.0]).double(); w1.requires_grad = True\n",
    "w2 = torch.tensor([1.0]).double(); w2.requires_grad = True\n",
    "b = torch.tensor([6.8813735870195432]).double(); b.requires_grad = True\n",
    "n = x1*w1 + x2*w2 + b\n",
    "o = torch.tanh(n)\n",
    "\n",
    "print(o.data.item()) # forward pass for o\n",
    "o.backward()\n",
    "\n",
    "print('_______')\n",
    "print(\"x1 grad:\", x1.grad.item())\n",
    "print(\"w1 grad:\", w1.grad.item())\n",
    "print(\"x2 grad:\", x2.grad.item())\n",
    "print(\"w2 grad:\", w2.grad.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f640de2",
   "metadata": {},
   "source": [
    "Now we will build our own two layered MLP from scratch. For that, we will build a neuron class first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52b36f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, nin): # nin: number of inputs\n",
    "        # initialize weights and bias\n",
    "        self.w = [Value(random.uniform(-1, 1)) for _ in range(nin)]\n",
    "        self.b = Value(random.uniform(-1, 1))\n",
    "    \n",
    "    def __call__(self, x):  # magic function to make the class object callable. Ex n = Neuron(), then we can call n(2)\n",
    "        # forward pass: w *  x + b\n",
    "        act = sum(wi*xi for wi, xi in zip(self.w, x)) + self.b   # raw activation\n",
    "        out = act.tanh()\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569511a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def __init__(self, nin, nout): # nin: number of inputs for each neuron, nout: number of neurons in the layer\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # we have to call neuron(x) for each neuron object\n",
    "       outs = [n(x) for n in self.neurons]\n",
    "       return outs[0] if len(outs) == 1 else outs\n",
    "   \n",
    "    def parameters(self):\n",
    "       return [p for neuron in self.neurons for p in neuron.parameters()] # list comprehension for the commented code\n",
    "    #    for neuron in self.neurons:\n",
    "    #        ps = neuron.parameters()\n",
    "    #        params.extend(ps)\n",
    "    #     return params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab580dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \n",
    "    def __init__(self, nin, nouts): # nin: number of inputs; nouts: size of each layer or no. of neurons in each layer. nouts is a list\n",
    "        sizes = [nin] + nouts # since, for the first layer, the input will go directly for the next layer, output of the previous layer would be the input. Hence, adding nin to sizes with nouts\n",
    "        self.layers = [Layer(sizes[i], sizes[i+1]) for i in range(len(nouts))]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) # output of the previous layer is input to the next layer\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "        # params = []\n",
    "        # for layer in self.layers:\n",
    "        #     ps = layer.parameters()\n",
    "        #     params.extend(ps)\n",
    "        # return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf32386c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=0.4841508722362814)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [-2.0, 4.0, 1]\n",
    "n = MLP(3, [4, 4, 1])\n",
    "n(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da2cce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n.parameters())\n",
    "# draw_dot(n(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e56f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.5109564441487823),\n",
       " Value(data=0.9533538738861984),\n",
       " Value(data=0.6417285493289414),\n",
       " Value(data=0.9180172243798411)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1,0, 0.5],\n",
    "    [-4.0, 0.5, 0],\n",
    "    [-1.0, -2.0, 4.0]\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # simulating a basic binary classification. These are ground truth\n",
    "\n",
    "ypred = [n(x) for x in xs]\n",
    "ypred # predictions after just one forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d9a4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating loss (mean squared error)\n",
    "# loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00539458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdc61d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n.layers[0].neurons[0].w[0].grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f201a8d",
   "metadata": {},
   "source": [
    "Basic steps to follow to train any neural network are:\n",
    "1. Forward Pass\n",
    "2. Backward Pass (we also flush the gradients to zero before the backward pass so that we do not keep on accumulating the gradients as by default they keep on adding)\n",
    "3. Update weights (using gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb7c727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, loss: 7.094052887503457\n",
      "1, loss: 7.0382409562991395\n",
      "2, loss: 6.976989453259534\n",
      "3, loss: 6.909762019463831\n",
      "4, loss: 6.836023255951915\n",
      "5, loss: 6.755271029370838\n",
      "6, loss: 6.667083543436086\n",
      "7, loss: 6.571183653854994\n",
      "8, loss: 6.467520680480008\n",
      "9, loss: 6.356365441085545\n",
      "10, loss: 6.238406958312895\n",
      "11, loss: 6.1148300268252145\n",
      "12, loss: 5.9873445740710585\n",
      "13, loss: 5.858136143405313\n",
      "14, loss: 5.729718310470841\n",
      "15, loss: 5.604694734970032\n",
      "16, loss: 5.485473438983873\n",
      "17, loss: 5.374001539077723\n",
      "18, loss: 5.271587843059746\n",
      "19, loss: 5.178850531220713\n",
      "20, loss: 5.095783491781082\n",
      "21, loss: 5.021900917411219\n",
      "22, loss: 4.956409001201527\n",
      "23, loss: 4.898363508017615\n",
      "24, loss: 4.846790948890476\n",
      "25, loss: 4.800768292677793\n",
      "26, loss: 4.759466714859188\n",
      "27, loss: 4.72216895819054\n",
      "28, loss: 4.688269776619725\n",
      "29, loss: 4.6572669693650495\n",
      "30, loss: 4.628748187725486\n",
      "31, loss: 4.602376717614025\n",
      "32, loss: 4.577878003729548\n",
      "33, loss: 4.555027743132365\n",
      "34, loss: 4.533641815198167\n",
      "35, loss: 4.513568009404666\n",
      "36, loss: 4.494679366307043\n",
      "37, loss: 4.47686889381337\n",
      "38, loss: 4.460045417737073\n",
      "39, loss: 4.444130346743561\n",
      "40, loss: 4.429055162451391\n",
      "41, loss: 4.414759477669847\n",
      "42, loss: 4.401189535673349\n",
      "43, loss: 4.388297049430977\n",
      "44, loss: 4.376038301450376\n",
      "45, loss: 4.364373442588218\n",
      "46, loss: 4.3532659423121665\n",
      "47, loss: 4.342682154033529\n",
      "48, loss: 4.332590967809352\n",
      "49, loss: 4.322963529421165\n",
      "50, loss: 4.313773009986181\n",
      "51, loss: 4.304994414184202\n",
      "52, loss: 4.29660441816332\n",
      "53, loss: 4.288581230437228\n",
      "54, loss: 4.2809044707778225\n",
      "55, loss: 4.273555063372007\n",
      "56, loss: 4.266515141454479\n",
      "57, loss: 4.259767961328237\n",
      "58, loss: 4.25329782420203\n",
      "59, loss: 4.247090004655479\n",
      "60, loss: 4.241130684822755\n",
      "61, loss: 4.235406893591121\n",
      "62, loss: 4.229906450260843\n",
      "63, loss: 4.224617912222936\n",
      "64, loss: 4.21953052629165\n",
      "65, loss: 4.214634183387909\n",
      "66, loss: 4.209919376313643\n",
      "67, loss: 4.205377160389953\n",
      "68, loss: 4.200999116757007\n",
      "69, loss: 4.196777318153101\n",
      "70, loss: 4.192704297005867\n",
      "71, loss: 4.1887730156814476\n",
      "72, loss: 4.184976838748288\n",
      "73, loss: 4.181309507121767\n",
      "74, loss: 4.177765113964257\n",
      "75, loss: 4.1743380822231115\n",
      "76, loss: 4.171023143696161\n",
      "77, loss: 4.167815319521164\n",
      "78, loss: 4.164709901991999\n",
      "79, loss: 4.161702437610442\n",
      "80, loss: 4.158788711288226\n",
      "81, loss: 4.155964731619428\n",
      "82, loss: 4.153226717148596\n",
      "83, loss: 4.150571083564844\n",
      "84, loss: 4.147994431756895\n",
      "85, loss: 4.14549353666847\n",
      "86, loss: 4.143065336897574\n",
      "87, loss: 4.140706924987166\n",
      "88, loss: 4.138415538358403\n",
      "89, loss: 4.136188550841083\n",
      "90, loss: 4.134023464759174\n",
      "91, loss: 4.1319179035323\n",
      "92, loss: 4.129869604756924\n",
      "93, loss: 4.127876413733562\n",
      "94, loss: 4.125936277408809\n",
      "95, loss: 4.124047238703243\n",
      "96, loss: 4.1222074311983885\n",
      "97, loss: 4.120415074157846\n",
      "98, loss: 4.118668467859553\n",
      "99, loss: 4.116965989217802\n",
      "100, loss: 4.115306087675189\n",
      "101, loss: 4.11368728134614\n",
      "102, loss: 4.112108153394973\n",
      "103, loss: 4.110567348632692\n",
      "104, loss: 4.109063570317879\n",
      "105, loss: 4.107595577148053\n",
      "106, loss: 4.106162180428908\n",
      "107, loss: 4.1047622414097\n",
      "108, loss: 4.103394668773903\n",
      "109, loss: 4.102058416275018\n",
      "110, loss: 4.100752480508198\n",
      "111, loss: 4.099475898808858\n",
      "112, loss: 4.098227747270284\n",
      "113, loss: 4.0970071388725735\n",
      "114, loss: 4.095813221715961\n",
      "115, loss: 4.094645177351942\n",
      "116, loss: 4.093502219206155\n",
      "117, loss: 4.092383591087284\n",
      "118, loss: 4.091288565776749\n",
      "119, loss: 4.090216443694237\n",
      "120, loss: 4.089166551634458\n",
      "121, loss: 4.088138241570863\n",
      "122, loss: 4.087130889522299\n",
      "123, loss: 4.086143894478864\n",
      "124, loss: 4.085176677383478\n",
      "125, loss: 4.084228680165885\n",
      "126, loss: 4.0832993648260425\n",
      "127, loss: 4.082388212564053\n",
      "128, loss: 4.081494722953929\n",
      "129, loss: 4.080618413158715\n",
      "130, loss: 4.079758817184622\n",
      "131, loss: 4.078915485171966\n",
      "132, loss: 4.078087982720851\n",
      "133, loss: 4.077275890249664\n",
      "134, loss: 4.076478802384586\n",
      "135, loss: 4.075696327378394\n",
      "136, loss: 4.0749280865569775\n",
      "137, loss: 4.074173713792047\n",
      "138, loss: 4.073432854998654\n",
      "139, loss: 4.072705167656168\n",
      "140, loss: 4.071990320351488\n",
      "141, loss: 4.071287992343293\n",
      "142, loss: 4.070597873146253\n",
      "143, loss: 4.0699196621341365\n",
      "144, loss: 4.069253068160864\n",
      "145, loss: 4.068597809198554\n",
      "146, loss: 4.0679536119917135\n",
      "147, loss: 4.067320211726758\n",
      "148, loss: 4.06669735171606\n",
      "149, loss: 4.0660847830958335\n",
      "150, loss: 4.065482264537127\n",
      "151, loss: 4.064889561969321\n",
      "152, loss: 4.06430644831546\n",
      "153, loss: 4.063732703238897\n",
      "154, loss: 4.063168112900653\n",
      "155, loss: 4.062612469727003\n",
      "156, loss: 4.062065572186782\n",
      "157, loss: 4.061527224577968\n",
      "158, loss: 4.060997236823056\n",
      "159, loss: 4.060475424272874\n",
      "160, loss: 4.059961607518393\n",
      "161, loss: 4.059455612210168\n",
      "162, loss: 4.05895726888508\n",
      "163, loss: 4.058466412800014\n",
      "164, loss: 4.0579828837721825\n",
      "165, loss: 4.057506526025755\n",
      "166, loss: 4.057037188044556\n",
      "167, loss: 4.056574722430508\n",
      "168, loss: 4.056118985767607\n",
      "169, loss: 4.055669838491158\n",
      "170, loss: 4.055227144762033\n",
      "171, loss: 4.054790772345762\n",
      "172, loss: 4.054360592496204\n",
      "173, loss: 4.05393647984364\n",
      "174, loss: 4.053518312287058\n",
      "175, loss: 4.053105970890485\n",
      "176, loss: 4.052699339783162\n",
      "177, loss: 4.052298306063426\n",
      "178, loss: 4.051902759706106\n",
      "179, loss: 4.051512593473347\n",
      "180, loss: 4.0511277028286345\n",
      "181, loss: 4.050747985853959\n",
      "182, loss: 4.05037334316996\n",
      "183, loss: 4.050003677858915\n",
      "184, loss: 4.04963889539049\n",
      "185, loss: 4.049278903550098\n",
      "186, loss: 4.04892361236981\n",
      "187, loss: 4.048572934061657\n",
      "188, loss: 4.048226782953282\n",
      "189, loss: 4.0478850754258024\n",
      "190, loss: 4.047547729853838\n",
      "191, loss: 4.047214666547575\n",
      "192, loss: 4.046885807696829\n",
      "193, loss: 4.046561077316997\n",
      "194, loss: 4.046240401196823\n",
      "195, loss: 4.045923706847956\n",
      "196, loss: 4.045610923456151\n",
      "197, loss: 4.045301981834129\n",
      "198, loss: 4.044996814375984\n",
      "199, loss: 4.044695355013087\n",
      "200, loss: 4.044397539171448\n",
      "201, loss: 4.0441033037304575\n",
      "202, loss: 4.043812586982973\n",
      "203, loss: 4.0435253285967026\n",
      "204, loss: 4.043241469576808\n",
      "205, loss: 4.042960952229722\n",
      "206, loss: 4.042683720128124\n",
      "207, loss: 4.042409718076993\n",
      "208, loss: 4.042138892080765\n",
      "209, loss: 4.041871189311511\n",
      "210, loss: 4.041606558078093\n",
      "211, loss: 4.041344947796296\n",
      "212, loss: 4.0410863089598825\n",
      "213, loss: 4.0408305931125295\n",
      "214, loss: 4.040577752820625\n",
      "215, loss: 4.040327741646913\n",
      "216, loss: 4.040080514124912\n",
      "217, loss: 4.039836025734123\n",
      "218, loss: 4.039594232875978\n",
      "219, loss: 4.039355092850514\n",
      "220, loss: 4.039118563833736\n",
      "221, loss: 4.038884604855648\n",
      "222, loss: 4.038653175778949\n",
      "223, loss: 4.038424237278332\n",
      "224, loss: 4.038197750820417\n",
      "225, loss: 4.037973678644238\n",
      "226, loss: 4.037751983742321\n",
      "227, loss: 4.037532629842294\n",
      "228, loss: 4.037315581389035\n",
      "229, loss: 4.037100803527324\n",
      "230, loss: 4.036888262084992\n",
      "231, loss: 4.036677923556543\n",
      "232, loss: 4.03646975508726\n",
      "233, loss: 4.0362637244577195\n",
      "234, loss: 4.0360598000687835\n",
      "235, loss: 4.035857950926974\n",
      "236, loss: 4.035658146630273\n",
      "237, loss: 4.035460357354314\n",
      "238, loss: 4.035264553838949\n",
      "239, loss: 4.035070707375181\n",
      "240, loss: 4.034878789792461\n",
      "241, loss: 4.034688773446326\n",
      "242, loss: 4.034500631206374\n",
      "243, loss: 4.034314336444558\n",
      "244, loss: 4.034129863023804\n",
      "245, loss: 4.03394718528692\n",
      "246, loss: 4.033766278045816\n",
      "247, loss: 4.033587116570994\n",
      "248, loss: 4.033409676581326\n",
      "249, loss: 4.033233934234104\n",
      "250, loss: 4.0330598661153365\n",
      "251, loss: 4.0328874492303095\n",
      "252, loss: 4.032716660994391\n",
      "253, loss: 4.032547479224074\n",
      "254, loss: 4.032379882128242\n",
      "255, loss: 4.032213848299675\n",
      "256, loss: 4.032049356706758\n",
      "257, loss: 4.031886386685405\n",
      "258, loss: 4.031724917931192\n",
      "259, loss: 4.031564930491689\n",
      "260, loss: 4.031406404758971\n",
      "261, loss: 4.031249321462341\n",
      "262, loss: 4.031093661661212\n",
      "263, loss: 4.030939406738185\n",
      "264, loss: 4.03078653839228\n",
      "265, loss: 4.030635038632347\n",
      "266, loss: 4.030484889770641\n",
      "267, loss: 4.030336074416542\n",
      "268, loss: 4.030188575470439\n",
      "269, loss: 4.030042376117759\n",
      "270, loss: 4.0298974598231405\n",
      "271, loss: 4.029753810324752\n",
      "272, loss: 4.029611411628734\n",
      "273, loss: 4.029470248003796\n",
      "274, loss: 4.029330303975921\n",
      "275, loss: 4.029191564323206\n",
      "276, loss: 4.029054014070828\n",
      "277, loss: 4.028917638486123\n",
      "278, loss: 4.028782423073779\n",
      "279, loss: 4.028648353571151\n",
      "280, loss: 4.028515415943672\n",
      "281, loss: 4.028383596380386\n",
      "282, loss: 4.028252881289573\n",
      "283, loss: 4.028123257294477\n",
      "284, loss: 4.027994711229143\n",
      "285, loss: 4.0278672301343255\n",
      "286, loss: 4.027740801253522\n",
      "287, loss: 4.027615412029069\n",
      "288, loss: 4.027491050098344\n",
      "289, loss: 4.027367703290048\n",
      "290, loss: 4.027245359620566\n",
      "291, loss: 4.027124007290422\n",
      "292, loss: 4.027003634680798\n",
      "293, loss: 4.026884230350145\n",
      "294, loss: 4.026765783030859\n",
      "295, loss: 4.026648281626041\n",
      "296, loss: 4.026531715206311\n",
      "297, loss: 4.026416073006712\n",
      "298, loss: 4.0263013444236675\n",
      "299, loss: 4.0261875190120175\n",
      "300, loss: 4.026074586482103\n",
      "301, loss: 4.025962536696933\n",
      "302, loss: 4.0258513596693986\n",
      "303, loss: 4.025741045559545\n",
      "304, loss: 4.0256315846719195\n",
      "305, loss: 4.025522967452965\n",
      "306, loss: 4.025415184488455\n",
      "307, loss: 4.025308226501015\n",
      "308, loss: 4.02520208434767\n",
      "309, loss: 4.025096749017452\n",
      "310, loss: 4.024992211629064\n",
      "311, loss: 4.024888463428579\n",
      "312, loss: 4.024785495787211\n",
      "313, loss: 4.024683300199101\n",
      "314, loss: 4.024581868279173\n",
      "315, loss: 4.024481191761027\n",
      "316, loss: 4.024381262494874\n",
      "317, loss: 4.024282072445514\n",
      "318, loss: 4.024183613690356\n",
      "319, loss: 4.024085878417482\n",
      "320, loss: 4.023988858923744\n",
      "321, loss: 4.0238925476129\n",
      "322, loss: 4.023796936993798\n",
      "323, loss: 4.023702019678586\n",
      "324, loss: 4.0236077883809545\n",
      "325, loss: 4.0235142359144325\n",
      "326, loss: 4.023421355190697\n",
      "327, loss: 4.023329139217932\n",
      "328, loss: 4.023237581099208\n",
      "329, loss: 4.023146674030897\n",
      "330, loss: 4.023056411301133\n",
      "331, loss: 4.022966786288277\n",
      "332, loss: 4.022877792459433\n",
      "333, loss: 4.022789423368982\n",
      "334, loss: 4.022701672657151\n",
      "335, loss: 4.022614534048605\n",
      "336, loss: 4.022528001351077\n",
      "337, loss: 4.022442068453999\n",
      "338, loss: 4.022356729327192\n",
      "339, loss: 4.022271978019559\n",
      "340, loss: 4.02218780865781\n",
      "341, loss: 4.02210421544521\n",
      "342, loss: 4.022021192660355\n",
      "343, loss: 4.021938734655967\n",
      "344, loss: 4.021856835857707\n",
      "345, loss: 4.021775490763029\n",
      "346, loss: 4.021694693940026\n",
      "347, loss: 4.021614440026332\n",
      "348, loss: 4.02153472372801\n",
      "349, loss: 4.021455539818494\n",
      "350, loss: 4.021376883137519\n",
      "351, loss: 4.0212987485901\n",
      "352, loss: 4.0212211311455075\n",
      "353, loss: 4.021144025836269\n",
      "354, loss: 4.021067427757201\n",
      "355, loss: 4.020991332064438\n",
      "356, loss: 4.020915733974489\n",
      "357, loss: 4.020840628763322\n",
      "358, loss: 4.020766011765442\n",
      "359, loss: 4.020691878373009\n",
      "360, loss: 4.020618224034953\n",
      "361, loss: 4.020545044256118\n",
      "362, loss: 4.0204723345964135\n",
      "363, loss: 4.020400090669988\n",
      "364, loss: 4.020328308144417\n",
      "365, loss: 4.020256982739887\n",
      "366, loss: 4.020186110228423\n",
      "367, loss: 4.020115686433117\n",
      "368, loss: 4.020045707227353\n",
      "369, loss: 4.019976168534085\n",
      "370, loss: 4.019907066325081\n",
      "371, loss: 4.019838396620217\n",
      "372, loss: 4.01977015548677\n",
      "373, loss: 4.019702339038715\n",
      "374, loss: 4.019634943436047\n",
      "375, loss: 4.01956796488412\n",
      "376, loss: 4.019501399632963\n",
      "377, loss: 4.019435243976657\n",
      "378, loss: 4.019369494252683\n",
      "379, loss: 4.019304146841306\n",
      "380, loss: 4.01923919816495\n",
      "381, loss: 4.019174644687604\n",
      "382, loss: 4.019110482914213\n",
      "383, loss: 4.019046709390111\n",
      "384, loss: 4.0189833207004355\n",
      "385, loss: 4.018920313469563\n",
      "386, loss: 4.018857684360554\n",
      "387, loss: 4.018795430074616\n",
      "388, loss: 4.018733547350555\n",
      "389, loss: 4.018672032964254\n",
      "390, loss: 4.018610883728148\n",
      "391, loss: 4.018550096490722\n",
      "392, loss: 4.018489668136005\n",
      "393, loss: 4.01842959558307\n",
      "394, loss: 4.018369875785564\n",
      "395, loss: 4.018310505731213\n",
      "396, loss: 4.018251482441358\n",
      "397, loss: 4.018192802970505\n",
      "398, loss: 4.018134464405851\n",
      "399, loss: 4.018076463866853\n",
      "400, loss: 4.018018798504771\n",
      "401, loss: 4.017961465502258\n",
      "402, loss: 4.0179044620729085\n",
      "403, loss: 4.017847785460866\n",
      "404, loss: 4.0177914329403865\n",
      "405, loss: 4.017735401815448\n",
      "406, loss: 4.017679689419348\n",
      "407, loss: 4.017624293114305\n",
      "408, loss: 4.017569210291081\n",
      "409, loss: 4.017514438368599\n",
      "410, loss: 4.017459974793557\n",
      "411, loss: 4.017405817040077\n",
      "412, loss: 4.017351962609327\n",
      "413, loss: 4.0172984090291814\n",
      "414, loss: 4.017245153853847\n",
      "415, loss: 4.017192194663539\n",
      "416, loss: 4.017139529064124\n",
      "417, loss: 4.017087154686794\n",
      "418, loss: 4.017035069187734\n",
      "419, loss: 4.016983270247795\n",
      "420, loss: 4.016931755572176\n",
      "421, loss: 4.016880522890112\n",
      "422, loss: 4.016829569954556\n",
      "423, loss: 4.016778894541881\n",
      "424, loss: 4.016728494451575\n",
      "425, loss: 4.016678367505949\n",
      "426, loss: 4.016628511549834\n",
      "427, loss: 4.016578924450315\n",
      "428, loss: 4.016529604096423\n",
      "429, loss: 4.016480548398877\n",
      "430, loss: 4.016431755289796\n",
      "431, loss: 4.016383222722438\n",
      "432, loss: 4.016334948670925\n",
      "433, loss: 4.016286931129993\n",
      "434, loss: 4.016239168114713\n",
      "435, loss: 4.016191657660263\n",
      "436, loss: 4.016144397821654\n",
      "437, loss: 4.0160973866735\n",
      "438, loss: 4.016050622309761\n",
      "439, loss: 4.016004102843509\n",
      "440, loss: 4.015957826406699\n",
      "441, loss: 4.015911791149923\n",
      "442, loss: 4.01586599524219\n",
      "443, loss: 4.015820436870696\n",
      "444, loss: 4.015775114240597\n",
      "445, loss: 4.015730025574806\n",
      "446, loss: 4.015685169113753\n",
      "447, loss: 4.015640543115191\n",
      "448, loss: 4.015596145853979\n",
      "449, loss: 4.0155519756218725\n",
      "450, loss: 4.015508030727321\n",
      "451, loss: 4.015464309495268\n",
      "452, loss: 4.015420810266955\n",
      "453, loss: 4.015377531399719\n",
      "454, loss: 4.015334471266806\n",
      "455, loss: 4.01529162825718\n",
      "456, loss: 4.015249000775331\n",
      "457, loss: 4.0152065872411\n",
      "458, loss: 4.0151643860894835\n",
      "459, loss: 4.0151223957704705\n",
      "460, loss: 4.015080614748847\n",
      "461, loss: 4.015039041504039\n",
      "462, loss: 4.01499767452993\n",
      "463, loss: 4.014956512334691\n",
      "464, loss: 4.014915553440622\n",
      "465, loss: 4.014874796383979\n",
      "466, loss: 4.01483423971481\n",
      "467, loss: 4.014793881996804\n",
      "468, loss: 4.014753721807127\n",
      "469, loss: 4.014713757736262\n",
      "470, loss: 4.014673988387861\n",
      "471, loss: 4.014634412378594\n",
      "472, loss: 4.014595028337998\n",
      "473, loss: 4.014555834908319\n",
      "474, loss: 4.0145168307443875\n",
      "475, loss: 4.014478014513457\n",
      "476, loss: 4.014439384895068\n",
      "477, loss: 4.014400940580912\n",
      "478, loss: 4.014362680274689\n",
      "479, loss: 4.014324602691971\n",
      "480, loss: 4.014286706560072\n",
      "481, loss: 4.01424899061791\n",
      "482, loss: 4.014211453615886\n",
      "483, loss: 4.01417409431574\n",
      "484, loss: 4.014136911490441\n",
      "485, loss: 4.014099903924045\n",
      "486, loss: 4.014063070411587\n",
      "487, loss: 4.014026409758947\n",
      "488, loss: 4.013989920782734\n",
      "489, loss: 4.01395360231017\n",
      "490, loss: 4.013917453178961\n",
      "491, loss: 4.0138814722372\n",
      "492, loss: 4.013845658343236\n",
      "493, loss: 4.013810010365569\n",
      "494, loss: 4.013774527182735\n",
      "495, loss: 4.013739207683203\n",
      "496, loss: 4.013704050765255\n",
      "497, loss: 4.013669055336891\n",
      "498, loss: 4.0136342203157165\n",
      "499, loss: 4.013599544628836\n",
      "500, loss: 4.013565027212761\n",
      "501, loss: 4.0135306670132955\n",
      "502, loss: 4.013496462985442\n",
      "503, loss: 4.013462414093302\n",
      "504, loss: 4.01342851930998\n",
      "505, loss: 4.013394777617483\n",
      "506, loss: 4.013361188006625\n",
      "507, loss: 4.013327749476939\n",
      "508, loss: 4.013294461036578\n",
      "509, loss: 4.013261321702222\n",
      "510, loss: 4.013228330498999\n",
      "511, loss: 4.013195486460382\n",
      "512, loss: 4.013162788628102\n",
      "513, loss: 4.013130236052077\n",
      "514, loss: 4.013097827790302\n",
      "515, loss: 4.013065562908781\n",
      "516, loss: 4.013033440481439\n",
      "517, loss: 4.0130014595900345\n",
      "518, loss: 4.0129696193240845\n",
      "519, loss: 4.012937918780777\n",
      "520, loss: 4.012906357064895\n",
      "521, loss: 4.01287493328874\n",
      "522, loss: 4.0128436465720485\n",
      "523, loss: 4.01281249604192\n",
      "524, loss: 4.012781480832735\n",
      "525, loss: 4.012750600086085\n",
      "526, loss: 4.0127198529507\n",
      "527, loss: 4.01268923858237\n",
      "528, loss: 4.012658756143875\n",
      "529, loss: 4.012628404804909\n",
      "530, loss: 4.012598183742024\n",
      "531, loss: 4.012568092138543\n",
      "532, loss: 4.012538129184498\n",
      "533, loss: 4.012508294076567\n",
      "534, loss: 4.012478586017996\n",
      "535, loss: 4.012449004218543\n",
      "536, loss: 4.0124195478944085\n",
      "537, loss: 4.012390216268166\n",
      "538, loss: 4.012361008568704\n",
      "539, loss: 4.012331924031161\n",
      "540, loss: 4.0123029618968635\n",
      "541, loss: 4.012274121413263\n",
      "542, loss: 4.012245401833872\n",
      "543, loss: 4.012216802418212\n",
      "544, loss: 4.012188322431745\n",
      "545, loss: 4.012159961145823\n",
      "546, loss: 4.012131717837617\n",
      "547, loss: 4.012103591790079\n",
      "548, loss: 4.012075582291861\n",
      "549, loss: 4.012047688637282\n",
      "550, loss: 4.012019910126257\n",
      "551, loss: 4.0119922460642465\n",
      "552, loss: 4.011964695762207\n",
      "553, loss: 4.011937258536527\n",
      "554, loss: 4.011909933708987\n",
      "555, loss: 4.011882720606695\n",
      "556, loss: 4.011855618562042\n",
      "557, loss: 4.011828626912648\n",
      "558, loss: 4.011801745001315\n",
      "559, loss: 4.011774972175972\n",
      "560, loss: 4.011748307789626\n",
      "561, loss: 4.011721751200317\n",
      "562, loss: 4.011695301771067\n",
      "563, loss: 4.011668958869835\n",
      "564, loss: 4.011642721869464\n",
      "565, loss: 4.011616590147639\n",
      "566, loss: 4.011590563086841\n",
      "567, loss: 4.011564640074299\n",
      "568, loss: 4.011538820501944\n",
      "569, loss: 4.011513103766374\n",
      "570, loss: 4.011487489268792\n",
      "571, loss: 4.011461976414979\n",
      "572, loss: 4.011436564615243\n",
      "573, loss: 4.011411253284375\n",
      "574, loss: 4.011386041841617\n",
      "575, loss: 4.011360929710609\n",
      "576, loss: 4.0113359163193465\n",
      "577, loss: 4.011311001100153\n",
      "578, loss: 4.01128618348963\n",
      "579, loss: 4.011261462928616\n",
      "580, loss: 4.0112368388621515\n",
      "581, loss: 4.011212310739441\n",
      "582, loss: 4.011187878013807\n",
      "583, loss: 4.011163540142662\n",
      "584, loss: 4.011139296587461\n",
      "585, loss: 4.0111151468136725\n",
      "586, loss: 4.011091090290734\n",
      "587, loss: 4.011067126492024\n",
      "588, loss: 4.01104325489482\n",
      "589, loss: 4.0110194749802615\n",
      "590, loss: 4.0109957862333205\n",
      "591, loss: 4.01097218814276\n",
      "592, loss: 4.010948680201107\n",
      "593, loss: 4.010925261904611\n",
      "594, loss: 4.010901932753216\n",
      "595, loss: 4.0108786922505235\n",
      "596, loss: 4.010855539903758\n",
      "597, loss: 4.010832475223741\n",
      "598, loss: 4.0108094977248525\n",
      "599, loss: 4.0107866069249996\n",
      "600, loss: 4.010763802345587\n",
      "601, loss: 4.010741083511485\n",
      "602, loss: 4.010718449950997\n",
      "603, loss: 4.010695901195833\n",
      "604, loss: 4.010673436781073\n",
      "605, loss: 4.010651056245141\n",
      "606, loss: 4.0106287591297765\n",
      "607, loss: 4.010606544980001\n",
      "608, loss: 4.010584413344091\n",
      "609, loss: 4.010562363773551\n",
      "610, loss: 4.010540395823082\n",
      "611, loss: 4.010518509050556\n",
      "612, loss: 4.010496703016984\n",
      "613, loss: 4.010474977286494\n",
      "614, loss: 4.010453331426302\n",
      "615, loss: 4.010431765006676\n",
      "616, loss: 4.0104102776009265\n",
      "617, loss: 4.010388868785369\n",
      "618, loss: 4.010367538139292\n",
      "619, loss: 4.010346285244946\n",
      "620, loss: 4.0103251096875105\n",
      "621, loss: 4.010304011055066\n",
      "622, loss: 4.0102829889385685\n",
      "623, loss: 4.010262042931833\n",
      "624, loss: 4.010241172631501\n",
      "625, loss: 4.010220377637017\n",
      "626, loss: 4.01019965755061\n",
      "627, loss: 4.010179011977264\n",
      "628, loss: 4.010158440524694\n",
      "629, loss: 4.010137942803325\n",
      "630, loss: 4.010117518426271\n",
      "631, loss: 4.010097167009307\n",
      "632, loss: 4.010076888170852\n",
      "633, loss: 4.010056681531941\n",
      "634, loss: 4.010036546716205\n",
      "635, loss: 4.010016483349851\n",
      "636, loss: 4.009996491061638\n",
      "637, loss: 4.009976569482854\n",
      "638, loss: 4.0099567182473015\n",
      "639, loss: 4.009936936991264\n",
      "640, loss: 4.009917225353503\n",
      "641, loss: 4.009897582975216\n",
      "642, loss: 4.009878009500033\n",
      "643, loss: 4.009858504573991\n",
      "644, loss: 4.009839067845509\n",
      "645, loss: 4.009819698965378\n",
      "646, loss: 4.009800397586729\n",
      "647, loss: 4.009781163365023\n",
      "648, loss: 4.00976199595803\n",
      "649, loss: 4.009742895025807\n",
      "650, loss: 4.009723860230681\n",
      "651, loss: 4.00970489123723\n",
      "652, loss: 4.009685987712263\n",
      "653, loss: 4.009667149324808\n",
      "654, loss: 4.009648375746083\n",
      "655, loss: 4.009629666649485\n",
      "656, loss: 4.009611021710574\n",
      "657, loss: 4.00959244060705\n",
      "658, loss: 4.009573923018738\n",
      "659, loss: 4.009555468627573\n",
      "660, loss: 4.009537077117575\n",
      "661, loss: 4.009518748174844\n",
      "662, loss: 4.00950048148753\n",
      "663, loss: 4.0094822767458265\n",
      "664, loss: 4.009464133641953\n",
      "665, loss: 4.009446051870132\n",
      "666, loss: 4.009428031126576\n",
      "667, loss: 4.009410071109476\n",
      "668, loss: 4.00939217151898\n",
      "669, loss: 4.009374332057181\n",
      "670, loss: 4.009356552428097\n",
      "671, loss: 4.00933883233766\n",
      "672, loss: 4.009321171493698\n",
      "673, loss: 4.0093035696059225\n",
      "674, loss: 4.0092860263859125\n",
      "675, loss: 4.009268541547093\n",
      "676, loss: 4.009251114804734\n",
      "677, loss: 4.009233745875925\n",
      "678, loss: 4.009216434479561\n",
      "679, loss: 4.009199180336337\n",
      "680, loss: 4.009181983168723\n",
      "681, loss: 4.009164842700959\n",
      "682, loss: 4.009147758659032\n",
      "683, loss: 4.0091307307706705\n",
      "684, loss: 4.009113758765325\n",
      "685, loss: 4.009096842374165\n",
      "686, loss: 4.009079981330044\n",
      "687, loss: 4.00906317536751\n",
      "688, loss: 4.009046424222784\n",
      "689, loss: 4.009029727633735\n",
      "690, loss: 4.009013085339886\n",
      "691, loss: 4.008996497082391\n",
      "692, loss: 4.008979962604021\n",
      "693, loss: 4.008963481649156\n",
      "694, loss: 4.008947053963773\n",
      "695, loss: 4.008930679295429\n",
      "696, loss: 4.008914357393253\n",
      "697, loss: 4.00889808800793\n",
      "698, loss: 4.008881870891697\n",
      "699, loss: 4.008865705798319\n",
      "700, loss: 4.008849592483086\n",
      "701, loss: 4.008833530702804\n",
      "702, loss: 4.008817520215769\n",
      "703, loss: 4.008801560781777\n",
      "704, loss: 4.008785652162086\n",
      "705, loss: 4.008769794119434\n",
      "706, loss: 4.008753986418006\n",
      "707, loss: 4.008738228823433\n",
      "708, loss: 4.008722521102777\n",
      "709, loss: 4.008706863024521\n",
      "710, loss: 4.0086912543585616\n",
      "711, loss: 4.008675694876194\n",
      "712, loss: 4.008660184350105\n",
      "713, loss: 4.008644722554356\n",
      "714, loss: 4.008629309264383\n",
      "715, loss: 4.008613944256978\n",
      "716, loss: 4.008598627310282\n",
      "717, loss: 4.008583358203776\n",
      "718, loss: 4.008568136718265\n",
      "719, loss: 4.008552962635877\n",
      "720, loss: 4.008537835740048\n",
      "721, loss: 4.008522755815511\n",
      "722, loss: 4.00850772264829\n",
      "723, loss: 4.008492736025692\n",
      "724, loss: 4.008477795736287\n",
      "725, loss: 4.00846290156991\n",
      "726, loss: 4.008448053317651\n",
      "727, loss: 4.00843325077184\n",
      "728, loss: 4.008418493726033\n",
      "729, loss: 4.008403781975025\n",
      "730, loss: 4.008389115314813\n",
      "731, loss: 4.008374493542607\n",
      "732, loss: 4.008359916456815\n",
      "733, loss: 4.008345383857031\n",
      "734, loss: 4.008330895544027\n",
      "735, loss: 4.008316451319756\n",
      "736, loss: 4.0083020509873215\n",
      "737, loss: 4.008287694350993\n",
      "738, loss: 4.008273381216179\n",
      "739, loss: 4.0082591113894255\n",
      "740, loss: 4.008244884678415\n",
      "741, loss: 4.008230700891945\n",
      "742, loss: 4.008216559839928\n",
      "743, loss: 4.008202461333384\n",
      "744, loss: 4.008188405184428\n",
      "745, loss: 4.008174391206265\n",
      "746, loss: 4.008160419213185\n",
      "747, loss: 4.008146489020545\n",
      "748, loss: 4.0081326004447755\n",
      "749, loss: 4.008118753303363\n",
      "750, loss: 4.008104947414843\n",
      "751, loss: 4.008091182598797\n",
      "752, loss: 4.008077458675844\n",
      "753, loss: 4.008063775467626\n",
      "754, loss: 4.008050132796815\n",
      "755, loss: 4.008036530487092\n",
      "756, loss: 4.008022968363143\n",
      "757, loss: 4.008009446250662\n",
      "758, loss: 4.007995963976328\n",
      "759, loss: 4.007982521367808\n",
      "760, loss: 4.007969118253753\n",
      "761, loss: 4.0079557544637785\n",
      "762, loss: 4.00794242982847\n",
      "763, loss: 4.0079291441793705\n",
      "764, loss: 4.007915897348977\n",
      "765, loss: 4.007902689170727\n",
      "766, loss: 4.007889519479001\n",
      "767, loss: 4.007876388109106\n",
      "768, loss: 4.007863294897285\n",
      "769, loss: 4.007850239680688\n",
      "770, loss: 4.007837222297385\n",
      "771, loss: 4.00782424258635\n",
      "772, loss: 4.007811300387457\n",
      "773, loss: 4.007798395541476\n",
      "774, loss: 4.007785527890063\n",
      "775, loss: 4.007772697275756\n",
      "776, loss: 4.007759903541966\n",
      "777, loss: 4.007747146532979\n",
      "778, loss: 4.007734426093941\n",
      "779, loss: 4.007721742070854\n",
      "780, loss: 4.0077090943105755\n",
      "781, loss: 4.007696482660805\n",
      "782, loss: 4.0076839069700885\n",
      "783, loss: 4.007671367087797\n",
      "784, loss: 4.0076588628641385\n",
      "785, loss: 4.007646394150143\n",
      "786, loss: 4.00763396079765\n",
      "787, loss: 4.0076215626593195\n",
      "788, loss: 4.007609199588615\n",
      "789, loss: 4.007596871439804\n",
      "790, loss: 4.007584578067941\n",
      "791, loss: 4.00757231932888\n",
      "792, loss: 4.0075600950792545\n",
      "793, loss: 4.007547905176482\n",
      "794, loss: 4.0075357494787465\n",
      "795, loss: 4.007523627845009\n",
      "796, loss: 4.00751154013499\n",
      "797, loss: 4.007499486209171\n",
      "798, loss: 4.0074874659287865\n",
      "799, loss: 4.007475479155818\n",
      "800, loss: 4.007463525752993\n",
      "801, loss: 4.0074516055837766\n",
      "802, loss: 4.007439718512369\n",
      "803, loss: 4.007427864403696\n",
      "804, loss: 4.007416043123413\n",
      "805, loss: 4.007404254537889\n",
      "806, loss: 4.007392498514209\n",
      "807, loss: 4.007380774920171\n",
      "808, loss: 4.007369083624275\n",
      "809, loss: 4.007357424495723\n",
      "810, loss: 4.00734579740441\n",
      "811, loss: 4.007334202220924\n",
      "812, loss: 4.007322638816542\n",
      "813, loss: 4.00731110706322\n",
      "814, loss: 4.007299606833595\n",
      "815, loss: 4.00728813800097\n",
      "816, loss: 4.007276700439325\n",
      "817, loss: 4.007265294023304\n",
      "818, loss: 4.007253918628204\n",
      "819, loss: 4.007242574129984\n",
      "820, loss: 4.007231260405251\n",
      "821, loss: 4.007219977331266\n",
      "822, loss: 4.007208724785927\n",
      "823, loss: 4.007197502647768\n",
      "824, loss: 4.007186310795966\n",
      "825, loss: 4.007175149110325\n",
      "826, loss: 4.007164017471275\n",
      "827, loss: 4.0071529157598675\n",
      "828, loss: 4.007141843857777\n",
      "829, loss: 4.007130801647287\n",
      "830, loss: 4.007119789011298\n",
      "831, loss: 4.007108805833311\n",
      "832, loss: 4.007097851997433\n",
      "833, loss: 4.007086927388371\n",
      "834, loss: 4.0070760318914225\n",
      "835, loss: 4.007065165392484\n",
      "836, loss: 4.00705432777803\n",
      "837, loss: 4.007043518935129\n",
      "838, loss: 4.007032738751422\n",
      "839, loss: 4.007021987115129\n",
      "840, loss: 4.007011263915041\n",
      "841, loss: 4.007000569040525\n",
      "842, loss: 4.006989902381502\n",
      "843, loss: 4.006979263828468\n",
      "844, loss: 4.006968653272465\n",
      "845, loss: 4.006958070605099\n",
      "846, loss: 4.006947515718521\n",
      "847, loss: 4.006936988505436\n",
      "848, loss: 4.006926488859087\n",
      "849, loss: 4.006916016673266\n",
      "850, loss: 4.006905571842293\n",
      "851, loss: 4.006895154261032\n",
      "852, loss: 4.006884763824867\n",
      "853, loss: 4.00687440042972\n",
      "854, loss: 4.006864063972033\n",
      "855, loss: 4.00685375434877\n",
      "856, loss: 4.006843471457408\n",
      "857, loss: 4.006833215195947\n",
      "858, loss: 4.006822985462889\n",
      "859, loss: 4.006812782157254\n",
      "860, loss: 4.0068026051785575\n",
      "861, loss: 4.006792454426824\n",
      "862, loss: 4.006782329802575\n",
      "863, loss: 4.006772231206827\n",
      "864, loss: 4.006762158541087\n",
      "865, loss: 4.006752111707356\n",
      "866, loss: 4.006742090608118\n",
      "867, loss: 4.0067320951463445\n",
      "868, loss: 4.006722125225482\n",
      "869, loss: 4.006712180749462\n",
      "870, loss: 4.006702261622684\n",
      "871, loss: 4.006692367750023\n",
      "872, loss: 4.006682499036822\n",
      "873, loss: 4.006672655388892\n",
      "874, loss: 4.006662836712502\n",
      "875, loss: 4.006653042914389\n",
      "876, loss: 4.006643273901743\n",
      "877, loss: 4.006633529582207\n",
      "878, loss: 4.006623809863884\n",
      "879, loss: 4.006614114655316\n",
      "880, loss: 4.006604443865501\n",
      "881, loss: 4.006594797403875\n",
      "882, loss: 4.006585175180318\n",
      "883, loss: 4.006575577105146\n",
      "884, loss: 4.006566003089114\n",
      "885, loss: 4.00655645304341\n",
      "886, loss: 4.006546926879651\n",
      "887, loss: 4.006537424509885\n",
      "888, loss: 4.006527945846581\n",
      "889, loss: 4.006518490802636\n",
      "890, loss: 4.006509059291362\n",
      "891, loss: 4.006499651226496\n",
      "892, loss: 4.006490266522185\n",
      "893, loss: 4.0064809050929915\n",
      "894, loss: 4.006471566853888\n",
      "895, loss: 4.006462251720255\n",
      "896, loss: 4.006452959607879\n",
      "897, loss: 4.006443690432948\n",
      "898, loss: 4.006434444112053\n",
      "899, loss: 4.0064252205621855\n",
      "900, loss: 4.006416019700725\n",
      "901, loss: 4.0064068414454574\n",
      "902, loss: 4.006397685714549\n",
      "903, loss: 4.006388552426561\n",
      "904, loss: 4.00637944150044\n",
      "905, loss: 4.006370352855514\n",
      "906, loss: 4.006361286411501\n",
      "907, loss: 4.00635224208849\n",
      "908, loss: 4.006343219806961\n",
      "909, loss: 4.0063342194877505\n",
      "910, loss: 4.006325241052086\n",
      "911, loss: 4.006316284421559\n",
      "912, loss: 4.006307349518129\n",
      "913, loss: 4.0062984362641245\n",
      "914, loss: 4.0062895445822395\n",
      "915, loss: 4.006280674395529\n",
      "916, loss: 4.006271825627411\n",
      "917, loss: 4.006262998201655\n",
      "918, loss: 4.006254192042399\n",
      "919, loss: 4.006245407074126\n",
      "920, loss: 4.006236643221673\n",
      "921, loss: 4.006227900410229\n",
      "922, loss: 4.006219178565333\n",
      "923, loss: 4.006210477612863\n",
      "924, loss: 4.00620179747905\n",
      "925, loss: 4.006193138090463\n",
      "926, loss: 4.006184499374011\n",
      "927, loss: 4.006175881256942\n",
      "928, loss: 4.00616728366684\n",
      "929, loss: 4.006158706531624\n",
      "930, loss: 4.006150149779548\n",
      "931, loss: 4.006141613339192\n",
      "932, loss: 4.006133097139468\n",
      "933, loss: 4.006124601109615\n",
      "934, loss: 4.006116125179194\n",
      "935, loss: 4.006107669278092\n",
      "936, loss: 4.006099233336515\n",
      "937, loss: 4.006090817284996\n",
      "938, loss: 4.006082421054375\n",
      "939, loss: 4.006074044575815\n",
      "940, loss: 4.00606568778079\n",
      "941, loss: 4.006057350601086\n",
      "942, loss: 4.006049032968806\n",
      "943, loss: 4.006040734816353\n",
      "944, loss: 4.006032456076443\n",
      "945, loss: 4.006024196682092\n",
      "946, loss: 4.006015956566627\n",
      "947, loss: 4.0060077356636725\n",
      "948, loss: 4.005999533907152\n",
      "949, loss: 4.005991351231291\n",
      "950, loss: 4.005983187570612\n",
      "951, loss: 4.0059750428599274\n",
      "952, loss: 4.00596691703435\n",
      "953, loss: 4.005958810029282\n",
      "954, loss: 4.005950721780412\n",
      "955, loss: 4.005942652223722\n",
      "956, loss: 4.0059346012954835\n",
      "957, loss: 4.005926568932246\n",
      "958, loss: 4.005918555070849\n",
      "959, loss: 4.005910559648412\n",
      "960, loss: 4.005902582602337\n",
      "961, loss: 4.005894623870302\n",
      "962, loss: 4.005886683390264\n",
      "963, loss: 4.005878761100458\n",
      "964, loss: 4.005870856939395\n",
      "965, loss: 4.005862970845852\n",
      "966, loss: 4.005855102758885\n",
      "967, loss: 4.0058472526178175\n",
      "968, loss: 4.00583942036224\n",
      "969, loss: 4.0058316059320145\n",
      "970, loss: 4.005823809267263\n",
      "971, loss: 4.005816030308377\n",
      "972, loss: 4.005808268996007\n",
      "973, loss: 4.0058005252710664\n",
      "974, loss: 4.005792799074732\n",
      "975, loss: 4.005785090348432\n",
      "976, loss: 4.005777399033858\n",
      "977, loss: 4.005769725072954\n",
      "978, loss: 4.005762068407919\n",
      "979, loss: 4.005754428981205\n",
      "980, loss: 4.005746806735518\n",
      "981, loss: 4.005739201613808\n",
      "982, loss: 4.005731613559282\n",
      "983, loss: 4.005724042515389\n",
      "984, loss: 4.0057164884258265\n",
      "985, loss: 4.005708951234535\n",
      "986, loss: 4.005701430885701\n",
      "987, loss: 4.005693927323752\n",
      "988, loss: 4.0056864404933545\n",
      "989, loss: 4.005678970339417\n",
      "990, loss: 4.005671516807088\n",
      "991, loss: 4.005664079841747\n",
      "992, loss: 4.005656659389018\n",
      "993, loss: 4.005649255394754\n",
      "994, loss: 4.005641867805038\n",
      "995, loss: 4.005634496566194\n",
      "996, loss: 4.00562714162477\n",
      "997, loss: 4.005619802927546\n",
      "998, loss: 4.005612480421529\n",
      "999, loss: 4.005605174053958\n"
     ]
    }
   ],
   "source": [
    "steps = 1000\n",
    "lr = 0.005\n",
    "n = MLP(3, [4, 4, 1]) # definition of the architecture\n",
    "for k in range(steps):\n",
    "    # forward pass\n",
    "    ypred = [n(x) for x in xs]\n",
    "    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n",
    "    \n",
    "    # backward pass\n",
    "    for p in n.parameters(): # making the grads zero so that gradients do not keep on accumulating on every step.\n",
    "        p.grad = 0.0\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for p in n.parameters():\n",
    "        p.data += -lr * p.grad # gradient descent\n",
    "    \n",
    "    print(f\"{k}, loss: {loss.data}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74dc33f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=-0.9994581364104314),\n",
       " Value(data=-0.944768099759621),\n",
       " Value(data=-0.952780984981874),\n",
       " Value(data=0.9501517670226062)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = [n(x) for x in xs]\n",
    "ypred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karpathy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
