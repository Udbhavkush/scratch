{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db312f0",
   "metadata": {},
   "source": [
    "This file is just to test the library structure of micrograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecfe93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from micrograd.nn import MLP\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981b99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(444)\n",
    "random.seed(444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b070996",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [-1.0, 2.0, 5.0],\n",
    "    [4.0, -3.0, 0.5],\n",
    "    [7.0, 2.0, -3.5],\n",
    "    [0.0, 6.0, 7.0]\n",
    "]\n",
    "yout = [1, -1, -1, 1]\n",
    "\n",
    "model = MLP(3, [4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e2b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=22.39633980424365, grad=0.0))\n",
      "0, loss: 22.39633980424365\n",
      "Value(data=5.000208626892048, grad=0.0))\n",
      "1, loss: 5.000208626892048\n",
      "Value(data=4.483022125452611, grad=0.0))\n",
      "2, loss: 4.483022125452611\n",
      "Value(data=4.06230028103578, grad=0.0))\n",
      "3, loss: 4.06230028103578\n",
      "Value(data=3.6967238700304836, grad=0.0))\n",
      "4, loss: 3.6967238700304836\n",
      "Value(data=3.3789328947403283, grad=0.0))\n",
      "5, loss: 3.3789328947403283\n",
      "Value(data=3.1054981251983413, grad=0.0))\n",
      "6, loss: 3.1054981251983413\n",
      "Value(data=2.861942447554008, grad=0.0))\n",
      "7, loss: 2.861942447554008\n",
      "Value(data=2.6447366693372407, grad=0.0))\n",
      "8, loss: 2.6447366693372407\n",
      "Value(data=2.4451138520009867, grad=0.0))\n",
      "9, loss: 2.4451138520009867\n",
      "Value(data=2.2570729626634485, grad=0.0))\n",
      "10, loss: 2.2570729626634485\n",
      "Value(data=2.081785852142571, grad=0.0))\n",
      "11, loss: 2.081785852142571\n",
      "Value(data=1.9178026341338157, grad=0.0))\n",
      "12, loss: 1.9178026341338157\n",
      "Value(data=1.7640754164102708, grad=0.0))\n",
      "13, loss: 1.7640754164102708\n",
      "Value(data=1.6198493846592243, grad=0.0))\n",
      "14, loss: 1.6198493846592243\n",
      "Value(data=1.4845852114394034, grad=0.0))\n",
      "15, loss: 1.4845852114394034\n",
      "Value(data=1.357895139791825, grad=0.0))\n",
      "16, loss: 1.357895139791825\n",
      "Value(data=1.2394867740680966, grad=0.0))\n",
      "17, loss: 1.2394867740680966\n",
      "Value(data=1.131564500722721, grad=0.0))\n",
      "18, loss: 1.131564500722721\n",
      "Value(data=1.0482569240864819, grad=0.0))\n",
      "19, loss: 1.0482569240864819\n",
      "Value(data=0.9709403022704203, grad=0.0))\n",
      "20, loss: 0.9709403022704203\n",
      "Value(data=0.8976265941931335, grad=0.0))\n",
      "21, loss: 0.8976265941931335\n",
      "Value(data=0.8311681105586123, grad=0.0))\n",
      "22, loss: 0.8311681105586123\n",
      "Value(data=0.7684884160685859, grad=0.0))\n",
      "23, loss: 0.7684884160685859\n",
      "Value(data=0.7105976929569697, grad=0.0))\n",
      "24, loss: 0.7105976929569697\n",
      "Value(data=0.6570993651960504, grad=0.0))\n",
      "25, loss: 0.6570993651960504\n",
      "Value(data=0.607639519728395, grad=0.0))\n",
      "26, loss: 0.607639519728395\n",
      "Value(data=0.5624100996850461, grad=0.0))\n",
      "27, loss: 0.5624100996850461\n",
      "Value(data=0.521202652092732, grad=0.0))\n",
      "28, loss: 0.521202652092732\n",
      "Value(data=0.4817957249665371, grad=0.0))\n",
      "29, loss: 0.4817957249665371\n",
      "Value(data=0.44544115666715955, grad=0.0))\n",
      "30, loss: 0.44544115666715955\n",
      "Value(data=0.41183139641807254, grad=0.0))\n",
      "31, loss: 0.41183139641807254\n",
      "Value(data=0.38074707896314786, grad=0.0))\n",
      "32, loss: 0.38074707896314786\n",
      "Value(data=0.35199615067262985, grad=0.0))\n",
      "33, loss: 0.35199615067262985\n",
      "Value(data=0.32540339427856346, grad=0.0))\n",
      "34, loss: 0.32540339427856346\n",
      "Value(data=0.30080748951040553, grad=0.0))\n",
      "35, loss: 0.30080748951040553\n",
      "Value(data=0.2780594527235937, grad=0.0))\n",
      "36, loss: 0.2780594527235937\n",
      "Value(data=0.25702149414436914, grad=0.0))\n",
      "37, loss: 0.25702149414436914\n",
      "Value(data=0.2375660808104771, grad=0.0))\n",
      "38, loss: 0.2375660808104771\n",
      "Value(data=0.2195751282062755, grad=0.0))\n",
      "39, loss: 0.2195751282062755\n",
      "Value(data=0.20293928214477336, grad=0.0))\n",
      "40, loss: 0.20293928214477336\n",
      "Value(data=0.18756708248599338, grad=0.0))\n",
      "41, loss: 0.18756708248599338\n",
      "Value(data=0.1738204774241321, grad=0.0))\n",
      "42, loss: 0.1738204774241321\n",
      "Value(data=0.16058567875701624, grad=0.0))\n",
      "43, loss: 0.16058567875701624\n",
      "Value(data=0.14839277898193215, grad=0.0))\n",
      "44, loss: 0.14839277898193215\n",
      "Value(data=0.13712466625966335, grad=0.0))\n",
      "45, loss: 0.13712466625966335\n",
      "Value(data=0.12670908749653775, grad=0.0))\n",
      "46, loss: 0.12670908749653775\n",
      "Value(data=0.11708157393981006, grad=0.0))\n",
      "47, loss: 0.11708157393981006\n",
      "Value(data=0.10818273310612889, grad=0.0))\n",
      "48, loss: 0.10818273310612889\n",
      "Value(data=0.09995767735645991, grad=0.0))\n",
      "49, loss: 0.09995767735645991\n",
      "Value(data=0.09235564727878445, grad=0.0))\n",
      "50, loss: 0.09235564727878445\n",
      "Value(data=0.08532968982415093, grad=0.0))\n",
      "51, loss: 0.08532968982415093\n",
      "Value(data=0.07883636946702305, grad=0.0))\n",
      "52, loss: 0.07883636946702305\n",
      "Value(data=0.07283550451319745, grad=0.0))\n",
      "53, loss: 0.07283550451319745\n",
      "Value(data=0.06728992448566014, grad=0.0))\n",
      "54, loss: 0.06728992448566014\n",
      "Value(data=0.06216524607440688, grad=0.0))\n",
      "55, loss: 0.06216524607440688\n",
      "Value(data=0.0574296658630314, grad=0.0))\n",
      "56, loss: 0.0574296658630314\n",
      "Value(data=0.05305376841753377, grad=0.0))\n",
      "57, loss: 0.05305376841753377\n",
      "Value(data=0.04901034853524154, grad=0.0))\n",
      "58, loss: 0.04901034853524154\n",
      "Value(data=0.04527424658860589, grad=0.0))\n",
      "59, loss: 0.04527424658860589\n",
      "Value(data=0.04182219599807279, grad=0.0))\n",
      "60, loss: 0.04182219599807279\n",
      "Value(data=0.03863268194777714, grad=0.0))\n",
      "61, loss: 0.03863268194777714\n",
      "Value(data=0.035701336385918825, grad=0.0))\n",
      "62, loss: 0.035701336385918825\n",
      "Value(data=0.03305096864716496, grad=0.0))\n",
      "63, loss: 0.03305096864716496\n",
      "Value(data=0.030518095955107606, grad=0.0))\n",
      "64, loss: 0.030518095955107606\n",
      "Value(data=0.028188203055470172, grad=0.0))\n",
      "65, loss: 0.028188203055470172\n",
      "Value(data=0.026036157546544373, grad=0.0))\n",
      "66, loss: 0.026036157546544373\n",
      "Value(data=0.02404813815204719, grad=0.0))\n",
      "67, loss: 0.02404813815204719\n",
      "Value(data=0.02221163740989595, grad=0.0))\n",
      "68, loss: 0.02221163740989595\n",
      "Value(data=0.020515125153436564, grad=0.0))\n",
      "69, loss: 0.020515125153436564\n",
      "Value(data=0.01894795421369401, grad=0.0))\n",
      "70, loss: 0.01894795421369401\n",
      "Value(data=0.017500287560494227, grad=0.0))\n",
      "71, loss: 0.017500287560494227\n",
      "Value(data=0.016163034872269836, grad=0.0))\n",
      "72, loss: 0.016163034872269836\n",
      "Value(data=0.014927795330572077, grad=0.0))\n",
      "73, loss: 0.014927795330572077\n",
      "Value(data=0.013786805264059801, grad=0.0))\n",
      "74, loss: 0.013786805264059801\n",
      "Value(data=0.012732889934298868, grad=0.0))\n",
      "75, loss: 0.012732889934298868\n",
      "Value(data=0.011759419021801592, grad=0.0))\n",
      "76, loss: 0.011759419021801592\n",
      "Value(data=0.010860265485119844, grad=0.0))\n",
      "77, loss: 0.010860265485119844\n",
      "Value(data=0.010029767521512904, grad=0.0))\n",
      "78, loss: 0.010029767521512904\n",
      "Value(data=0.009262693390062464, grad=0.0))\n",
      "79, loss: 0.009262693390062464\n",
      "Value(data=0.008554208880632158, grad=0.0))\n",
      "80, loss: 0.008554208880632158\n",
      "Value(data=0.007899847230030092, grad=0.0))\n",
      "81, loss: 0.007899847230030092\n",
      "Value(data=0.0072954813022121, grad=0.0))\n",
      "82, loss: 0.0072954813022121\n",
      "Value(data=0.006737297863240085, grad=0.0))\n",
      "83, loss: 0.006737297863240085\n",
      "Value(data=0.006221773794371846, grad=0.0))\n",
      "84, loss: 0.006221773794371846\n",
      "Value(data=0.005745654098309275, grad=0.0))\n",
      "85, loss: 0.005745654098309275\n",
      "Value(data=0.005305931564395236, grad=0.0))\n",
      "86, loss: 0.005305931564395236\n",
      "Value(data=0.004899827968505571, grad=0.0))\n",
      "87, loss: 0.004899827968505571\n",
      "Value(data=0.0045298769328787885, grad=0.0))\n",
      "88, loss: 0.0045298769328787885\n",
      "Value(data=0.0041892266409065005, grad=0.0))\n",
      "89, loss: 0.0041892266409065005\n",
      "Value(data=0.003867046354375783, grad=0.0))\n",
      "90, loss: 0.003867046354375783\n",
      "Value(data=0.00357092637833563, grad=0.0))\n",
      "91, loss: 0.00357092637833563\n",
      "Value(data=0.0032974960227586643, grad=0.0))\n",
      "92, loss: 0.0032974960227586643\n",
      "Value(data=0.003044993246100077, grad=0.0))\n",
      "93, loss: 0.003044993246100077\n",
      "Value(data=0.002811813375670008, grad=0.0))\n",
      "94, loss: 0.002811813375670008\n",
      "Value(data=0.002596477715402599, grad=0.0))\n",
      "95, loss: 0.002596477715402599\n",
      "Value(data=0.0023976216074152786, grad=0.0))\n",
      "96, loss: 0.0023976216074152786\n",
      "Value(data=0.0022139849707579267, grad=0.0))\n",
      "97, loss: 0.0022139849707579267\n",
      "Value(data=0.002044404063805387, grad=0.0))\n",
      "98, loss: 0.002044404063805387\n",
      "Value(data=0.0018878040490413572, grad=0.0))\n",
      "99, loss: 0.0018878040490413572\n"
     ]
    }
   ],
   "source": [
    "steps = 100\n",
    "lr = 0.01\n",
    "\n",
    "for k in range(steps):\n",
    "    # forward pass\n",
    "    ypred = [model(x) for x in xs]\n",
    "    # MSE\n",
    "    loss = sum(((pred - target)**2 for target, pred in zip(yout, ypred)))\n",
    "    print(loss)\n",
    "    \n",
    "    # backward pass\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # update parameters\n",
    "    for p in model.parameters():\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    print(f\"{k}, loss: {loss.data}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61a4f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(data=0.9705280034092736, grad=0.0)), Value(data=-0.9977892642078782, grad=0.0)), Value(data=-0.9989475428583857, grad=0.0)), Value(data=0.9705280034092736, grad=0.0))]\n"
     ]
    }
   ],
   "source": [
    "y_final_pred = [model(x) for x in xs]\n",
    "print(y_final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb74064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karpathy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
